# -*- coding: utf-8 -*-
"""Proyek Analisis Data Afif Elqudsi

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vaYKJuk6CB26eeD8IjeRbIxGLKP1auI_

# Proyek Analisis Data: E-Commerce Public Dataset
- Nama: Afif elqudsi
- Email: afifelqudsi1166@gmail.com
- Id Dicoding: 4EXG45RWDPRL

## Menentukan Pertanyaan Bisnis

- pertanyaan 1 = apakah ada korelasi dari Harga dan Permintaan produk oleh customer???
- pertanyaan 2 = apa produk yang paling banyak terjuan??

## Menyaipkan semua library yang dibuthkan
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pyspark
!pip install pygal
!pip install cairosvg

!pip install streamlit

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
from pyspark import SparkConf, SparkContext
from pyspark.sql.functions import *
from pyspark.sql import SparkSession
import ipywidgets as widgets
from ipywidgets import interact, interactive
import pygal
spark = SparkSession.builder.appName("E-Commerce Analysis").getOrCreate()
import streamlit as st

"""## Data Wrangling

### Gathering Data

IMPORT DATA REVIEW DAN INFO DATA
"""

reviews_df = spark.read.option("delimeter","|").csv('/content/drive/MyDrive/Colab Notebooks/DataSet/order_reviews_dataset.csv',header = True)
reviews_df = reviews_df.withColumn('review_creation_date',to_timestamp('review_creation_date')).withColumn('review_answer_timestamp',to_timestamp('review_answer_timestamp'))
reviews_df = reviews_df.na.drop(subset=['review_creation_date','review_answer_timestamp'])
reviews_df.printSchema()
reviews_df.show()

"""IMPORT DATA PAYMENT DAN INFO DATA"""

payment_df = spark.read.option("delimeter","|").csv('/content/drive/MyDrive/Colab Notebooks/DataSet/order_payments_dataset.csv',header = True)
payment_df = payment_df.na.drop()
payment_df.printSchema()
payment_df.show()

"""IMPORT DATA ORDER DAN INFO DATA"""

orders_df = spark.read.option("delimeter","|").csv('/content/drive/MyDrive/Colab Notebooks/DataSet/orders_dataset.csv',header = True)
orders_df = orders_df.withColumn('order_purchase_timestamp', to_timestamp('order_purchase_timestamp')).withColumn('order_delivered_carrier_data', to_timestamp('order_delivered_carrier_date')).withColumn('order_approved_at',to_timestamp('order_approved_at')).withColumn('order_delivered_customer_date',to_timestamp('order_delivered_customer_date')).withColumn('order_estimed_delivery_date',to_timestamp('order_estimated_delivery_date'))
orders_df.printSchema()
orders_df.show()

"""IMPORT DATA CUSTOMERS DAN INFO DATA"""

customers_df = spark.read.option("delimeter","|").csv('/content/drive/MyDrive/Colab Notebooks/DataSet/customers_dataset.csv',header = True)
customers_df = customers_df.na.drop()
customers_df.printSchema()
customers_df.show()

"""IMPORT DATA PRODUCT DAN INFO DATA"""

products_df = spark.read.option("delimeter","|").csv('/content/drive/MyDrive/Colab Notebooks/DataSet/products_dataset.csv',header = True)
products_df = products_df.na.drop()
products_df.printSchema()
products_df.show()

"""IMPORT DATA ITEM DAN INFO DATA"""

item_df = spark.read.option("delimeter","|").csv('/content/drive/MyDrive/Colab Notebooks/DataSet/order_items_dataset.csv',header = True).dropna()
item_df=item_df.withColumn('shipping_limit_date',to_timestamp('shipping_limit_date')).withColumn('order_item_id',item_df.order_item_id.cast('int'))
item_df.printSchema()
item_df.show()

"""IMPORT DATA SELLERS DAN INFO DATA"""

sellers_df = spark.read.option("delimeter","|").csv('/content/drive/MyDrive/Colab Notebooks/DataSet/sellers_dataset.csv',header = True).dropna()
sellers_df.printSchema()
sellers_df.show()

"""IMPORT DATA GEOLOCATIONS DAN INFO DATA"""

geolocation_df = spark.read.csv("/content/drive/MyDrive/Colab Notebooks/DataSet/geolocation_dataset.csv",header = True)
geolocation_df = sellers_df.join(geolocation_df).where(sellers_df['seller_zip_code_prefix']==geolocation_df['geolocation_zip_code_prefix']).drop(*('seller_id','seller_zip_code_prefix','seller_state','geolocation_city')).withColumnRenamed('seller_city','geolocation_city')
geolocation_df = geolocation_df.select('geolocation_zip_code_prefix','geolocation_lat','geolocation_lng','geolocation_city','geolocation_state')
geolocation_df.show()

"""IMPORT DATA TRANSLATION DAN INFO DATA BESERTA PENJUALAN TERATAS"""

translation_df = spark.read.csv("/content/drive/MyDrive/Colab Notebooks/DataSet/product_category_name_translation.csv",header = True)
order_item_grpby = item_df.groupBy('product_id').agg({'order_item_id':'max'})
top_selling = order_item_grpby.join(products_df,['product_id'])
top_selling = top_selling.join(translation_df,['product_category_name'])
top_selling = top_selling.groupBy('product_category_name_english').agg({'max(order_item_id)':'max'}).withColumnRenamed('max(max(order_item_id))','order_item').withColumnRenamed('product_category_name_english','Product_Name')
top_selling.orderBy('order_item',ascending=False).show()

"""### Assessing Data

menilai data order review
"""

reviews_df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/order_reviews_dataset.csv')
reviews_df.info()
reviews_df.isna().sum()
print("Jumlah duplikasi: ", reviews_df.duplicated().sum())
reviews_df.describe()

"""MENILAI DATA PAYMENT"""

payment_df =pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/order_payments_dataset.csv')
payment_df.info()
payment_df.isna().sum()
print("Jumlah duplikasi: ", payment_df.duplicated().sum())
payment_df.describe()

orders_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/orders_dataset.csv')
orders_df.info()
orders_df.isna().sum()
print("Jumlah duplikasi: ", orders_df.duplicated().sum())
orders_df.describe()

"""MENILAI DATA CUSTOMERS"""

customers_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/customers_dataset.csv')
customers_df.info()
customers_df.isna().sum()
print("Jumlah duplikasi: ", customers_df.duplicated().sum())
customers_df.describe()

"""MENILAI DATA PRODUCT"""

products_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/products_dataset.csv')
products_df.info()
products_df.isna().sum()
print("Jumlah duplikasi: ", products_df.duplicated().sum())
products_df.describe()

"""MENILAI DATA ITEM"""

item_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/order_items_dataset.csv')
item_df.info()
item_df.isna().sum()
print("Jumlah duplikasi: ", item_df.duplicated().sum())
item_df.describe()

"""MENILAI DATA SELLER"""

sellers_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/sellers_dataset.csv')
sellers_df.info()
sellers_df.isna().sum()
print("Jumlah duplikasi: ", sellers_df.duplicated().sum())
sellers_df.describe()

"""MENILAI DATA GEOLOCATION"""

geolocation_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/geolocation_dataset.csv')
geolocation_df.info()
geolocation_df.isna().sum()
print("Jumlah duplikasi: ", geolocation_df.duplicated().sum())
geolocation_df.describe()

"""MENILAI DATA TRANSLATION PRODUCT NAME"""

translation_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSet/product_category_name_translation.csv')
translation_df.info()
translation_df.isna().sum()
print("Jumlah duplikasi: ", translation_df.duplicated().sum())
translation_df.describe()

"""### Cleaning Data

CLEANING DATA REVIEW YANG ADA MISSING VALUES
"""

#metode imputasi data yang mengatasi missing value pada data
reviews_df.review_comment_title.value_counts()

reviews_df.review_comment_message.value_counts()

reviews_df.fillna(value="Recomendo", inplace=True)

reviews_df.fillna(value="Muito bom", inplace=True)

reviews_df.isna().sum()

#HANYA PADA DATA REVIEW SAJA DITEMUKAN MISSING VALUES SELAIN DARI ITU AMAN

"""## Exploratory Data Analysis (EDA)

### Explore ...

**Total Orders by Product Category**
"""

product_category = item_df.join(products_df,['product_id'])
product_category = product_category.join(translation_df,['product_category_name'])
product_category = product_category.groupBy('product_category_name_english').count().withColumnRenamed('count','Total_item').withColumnRenamed('product_category_name_english','Product_Category')
product_category.show()

"""**Total Number Of Customers By Region**"""

Customer_by_region_state = customers_df.groupBy('customer_state').count().withColumnRenamed('count','No_of_customers').show()

from pyspark.sql import SparkSession
import matplotlib.pyplot as plt
import pandas as pd

# Inisialisasi sesi Spark
spark = SparkSession.builder.appName("example").getOrCreate()

# Load data ke DataFrame Spark (gantilah 'your_data.csv' dengan nama file Anda)
customers_df = spark.read.csv('/content/drive/MyDrive/Colab Notebooks/DataSet/customers_dataset.csv', header=True, inferSchema=True)

# Lakukan operasi grup dan hitung
Customer_by_region_state = customers_df.groupBy('customer_state').count().withColumnRenamed('count', 'No_of_customers')

# Konversi ke Pandas DataFrame
customer_by_region_state_pd = Customer_by_region_state.toPandas()

# Membuat plot batang
plt.figure(figsize=(12, 6))
plt.bar(customer_by_region_state_pd['customer_state'], customer_by_region_state_pd['No_of_customers'])
plt.xlabel('Customer State')
plt.ylabel('Number of Customers')
plt.title('Number of Customers by State')
plt.xticks(rotation=45, ha="right")
plt.tight_layout()

# Menampilkan plot
plt.show()

Customer_by_region_city = customers_df.groupBy('customer_city').count().orderBy('count',ascending=False).withColumnRenamed('count','No_of_customers').show()

"""**Most Valued Customer and Salesman**"""

orders_df_filter = orders_df.filter(orders_df.order_status=='delivered')
Most_fav = orders_df_filter.join(item_df,['order_id']).drop(*('order_status','order_purchase_timestamp','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','shipping_limit_date','price','freight_value'))
Most_fav_customer = Most_fav.groupBy('Customer_id').count().withColumnRenamed('count','total_product_buy')
Most_fav_customer.orderBy('total_product_buy',ascending=False).show()

Most_fav_seller = Most_fav.groupBy('seller_id').count().withColumnRenamed('count','total_product_sold')
Most_fav_seller.orderBy('total_product_sold',ascending=False).show()

"""**Total Order By Regions/Cities**"""

Order_by_region = customers_df.join(orders_df_filter,['customer_id'],'leftsemi')
Customer_by_region_city = Order_by_region.groupBy('customer_city').count()
Customer_by_region_city.orderBy('count',ascending=False).withColumnRenamed('count','Total_orders').show()
Customer_by_region_city.sample(0.01).show()

"""**Min and Max Priced Products**"""

minmax = item_df.groupBy('product_id').agg({'price':'min'})
product_priced = minmax.join(products_df,['product_id'])
product_priced = product_priced.join(translation_df,['product_category_name'])
product_priced = product_priced.groupBy('product_category_name_english').agg({'min(price)':'min'}).withColumnRenamed('min(min(price))','Price').withColumnRenamed('product_category_name_english','Product_Name')
product_priced.orderBy('Price',ascending=True).show()


minmax = item_df.groupBy('product_id').agg({'price':'max'})
product_priced = minmax.join(products_df,['product_id'])
product_priced = product_priced.join(translation_df,['product_category_name'])
product_priced = product_priced.groupBy('product_category_name_english').agg({'max(price)':'max'}).withColumnRenamed('max(max(price))','Price').withColumnRenamed('product_category_name_english','Product_Name')
product_priced.orderBy('Price',ascending=False).show()

"""**Returning Customer to Understand Customer Loyalty**"""

Return = orders_df.filter(orders_df.order_status=='delivered')
Loyalty = Return.join(item_df,['order_id']).drop(*('order_status','order_purchase_timestamp','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date','shipping_limit_date','price','freight_value'))
Loyalty = Loyalty.groupBy('Customer_id').count().withColumnRenamed('count','total_product_buy')
print("The Most Valuable Customer is: ",Loyalty.orderBy('total_product_buy').tail(1))
Loyalty.orderBy('total_product_buy',ascending=False).show()

"""## Visualization & Explanatory Analysis

### Pertanyaan 1:

**Analysis of Product vs Sales/Profit**
"""

month_yr = orders_df.withColumn('Month_year',date_format('order_purchase_timestamp','M')).withColumn('Year',year('order_purchase_timestamp'))
month_yr = month_yr.select('order_id','customer_id','Month_year','Year',concat(col('year'),lit('-'),trim(col('Month_year'))).alias('MY')).select('order_id','MY').withColumn('MY',to_date('MY'))
month_yr = month_yr.join(item_df,['order_id'])

Analysis = month_yr.drop('order_item_id').withColumn('Total_Price',month_yr['price']+month_yr['freight_value'])
Analysis = Analysis.groupBy('MY').agg({'order_id':'count','price':'sum','freight_value':'sum','Total_Price':'sum'})
Analysis = Analysis.withColumn('price_per_product',Analysis['sum(Total_price)']/Analysis['count(order_id)']).withColumn('freight_per_product',Analysis['sum(freight_value)']/Analysis['count(order_id)']).withColumnRenamed('sum(Total_price)','Total_price').withColumnRenamed('count(order_id)','Order_id').withColumnRenamed('sum(freight_value)','freight_value').withColumnRenamed('sum(price)','price').orderBy('MY',ascending=True)
Analysis = Analysis.withColumn("Year",year('MY')).withColumn('price',Analysis.price.cast('int'))

from plotly.subplots import make_subplots
import plotly.graph_objects as go

Analysis_80_20 = Analysis.filter(Analysis['Year']==2017)
list_date_a = Analysis_80_20.select('MY').rdd.flatMap(lambda x:x).collect()
list_date_count_a = Analysis_80_20.select('price').rdd.flatMap(lambda x:x).collect()
list_orders = Analysis_80_20.select('order_id').rdd.flatMap(lambda x:x).collect()


fig = go.Figure()
fig = make_subplots(specs=[[{'secondary_y':True}]])
fig.add_trace(
    go.Scatter(
        x = [str(x) for x in list_date_a],
        y = [x for x in list_date_count_a],
        name='Price',
        text = [x for x in list_date_count_a],

    ),secondary_y=False,)
fig.add_trace(
    go.Bar(
        x = [str(x) for x in list_date_a],
        y = [x for x in list_orders],
        name='order',
        text = [x for x in list_orders]

    ),
    secondary_y=True,
)
fig.update_layout(
    autosize=False,
    width = 1000,
    height = 500,
    title = 'Orders and Price',
    xaxis_title = ' Year-Month',
    yaxis_title = 'Price'

)
fig.update_yaxes(automargin=True,title_text='Product count',secondary_y=True)
fig.show()

"""**KORELASI DARI Price dan Order**"""

# Data harga (Price) dari plot
price_data = np.array(list_date_count_a)

# Data jumlah pesanan (Order) dari plot
order_data = np.array(list_orders)

# Menghitung korelasi Pearson
correlation_coefficient = np.corrcoef(price_data, order_data)[0, 1]

print("Korelasi antara Price dan Order:", correlation_coefficient)

"""### Pertanyaan 2:

**Visualisasi Total Orders by Product Category dan product apa yang paling banyak terjual**
"""

import matplotlib.pyplot as plt
import pandas as pd

# Konversi data product_category ke Pandas DataFrame
product_category_pd = product_category.toPandas()

# Membuat plot batang
plt.figure(figsize=(12, 6))
plt.bar(product_category_pd['Product_Category'], product_category_pd['Total_item'])
plt.xlabel('Product Category')
plt.ylabel('Total Items')
plt.title('Total Items by Product Category')
plt.xticks(rotation=90, ha="right")
plt.tight_layout()

# Menampilkan plot
plt.show()

"""## Conclusion

- Conclution pertanyaan 1 = Korelasi antara Price dan Order: 0.9949314886807198 bisa dibulatkan menjadi 1, jadi terdapat hubungan antar Harga dan Permintaan produk oleh customer
- conclution pertanyaan 2 = produk yang banyak terjual yaitu bed_bath_table
"""

